% Desarrollo

Este capítulo describe el proceso de diseño, implementación y configuración de la estación de carga modular y la instrumentación del dron. Se detallan las metodologías y herramientas utilizadas para llevar a cabo el desarrollo, con un enfoque en la creación de una solución eficaz para el sistema de carga.

\section{Diseño y Desarrollo de la Base de Carga}
\subsection{Especificaciones y Requerimientos}
A continuación se presentan las especificaciones técnicas y los requisitos para la base de carga, garantizando compatibilidad y eficiencia para un sistema de carga en enjambres de drones:
    \begin{enumerate}
        \item Diseño modular y apilable para facilitar el almacenamiento de múltiples drones en un mismo metro cuadrado.
        \item Las dimensiones mínimas requeridas para la estacion de carga debe ser de mínimo 10 porciento mayores en ancho, largo y alto que las del drone.
        \item La estacion de carga deberá contar con un mecanismo de carga para la recarga de la batería del dron.
        \item Debe contar con por lo menos un método de posicionamiento visible para el drone.
    \end{enumerate}

    \subsection{Lista de Materiales}
    \begin{itemize}
        \item Perfiles de Aluminio
            \begin{itemize}
                \item \textbf{30 mm:}
                \begin{itemize}
                \item 4 x Perfiles de 100 mm
                \item 4 x Perfiles de 810 mm
                \item 6 x Perfiles de 750 mm
                \end{itemize}
                \item \textbf{40 mm:}
                \begin{itemize}
                \item 2 x Perfiles de 1040 mm
                \item 4 x Perfiles de 560 mm
                \item 4 x Perfiles de 830 mm
                \item 4 x Perfiles de 1120 mm
                \end{itemize}
            \end{itemize}
        \item 16 x Codos para perfil de aluminio impresos en 3D
        \item Tronillería para perfil de aluminio
        \item 2 x Riel Corredera Telescópica
        \item 1 x Motor de 12V
        \item 1 x Soportes de Motor impresos en 3D
        \item 1 x Banda de 1 m 
        \item 2 x Polea tipo A con diámetro interno de 1/2"
        \item 2 x Balero de DI: 15 mm y DE: 35 mm
        \item 2 x Chumacera impresa en 3D
        \item 2 x MDF de 9 mm de 75x75 cm
        \item 8 x Separadores de MDF impresos en 3D
        \item 1 x Fuente de Poder de 12V
        \item 1 x Arduino Mega
        \item 1 x Raspberry Pi 4
        \item 1 x Puente H BTS7960 
        \item 2 x Sensor de Proximidad Inductivo
        \item 1 x Joystick
        \item 1 x Router WiFi
        \item 1 x BT3 Pro Compact Charger
        \item 1 X Cable Carrier 1 m
    \end{itemize}

\subsection{Selección e Implementación del Mecanismo de Movimiento del Cajón}

En la sección 2.2.3 se explican en detalle los diferentes mecanismos de movimiento que se consideraron para la estación de carga, evaluando sus ventajas y desventajas en términos de precisión, durabilidad, costo y facilidad de integración en el diseño modular. Se analizaron opciones como pistones lineales, bandas dentadas y otros sistemas de transmisión, con el objetivo de seleccionar una solución que cumpliera con los requisitos de funcionalidad sin elevar demasiado los costos. 
Tras esta evaluación, se optó por un mecanismo de Polea y Banda tipo V, el cual, además de ser una opción económica, utiliza componentes ya disponibles, como el motor. Este sistema permite un movimiento horizontal suficiente para posicionar el dron con la precisión necesaria para el proceso de carga, a la vez que facilita el apilamiento modular de la estación. La orientación del movimiento no obstruye la estructura general de la estación, lo cual asegura que el diseño cumpla con el requisito de apilabilidad y compatibilidad en espacios compartidos, manteniéndose compacto y adaptable sin comprometer la estructura modular de la estación.

Para este mecanismo, se seleccionaron diferentes componentes, incluyendo una banda de alta resistencia para soportar las cargas previstas, poleas (con baja fricción) para optimizar el movimiento y reducir el desgaste del sistema en operaciones continuas, y un motor ... que tiene un torque de ... y cumple con el torque necesario para mover los 3 kg de peso del drone.

\subsubsection{Diseños CAD y Componentes}
    \begin{enumerate}
        \item Motor de 12V
        \item Poleas
        \item Banda
        \item Baleros
        \item Chumaceras 
        \item Soporte del Motor
    \end{enumerate}

\subsubsection{Mecanismo Polea y Banda tipo V}
(Imagen del Mecanismo)

\subsection{Diseño CAD de la Base de Carga}
Para cumplir con los requerimientos de diseño modular / apilable y compatibilidad con el drone en cuestión a las dimensiones de este. Se llevó a cabo el siguiente diseño en CAD:

    \begin{itemize}
        \item     El diseño de la estructura principal de la estación de carga se realizó en Fusion 360, considerando las dimensiones mínimas requeridas para el dron y el mecanismo de carga.
        Imagen
        \item     Se tomó en cuenta la dimensión necesaria para que el drone tenga un espacio de por lo menos 10 cm de separacion con la pared del cajón, esto para evitar alguna colusión del drone con la estructura de la base de carga al momento de intentar aterrizar, además se disminuyú la altura del cajón para que el drone pueda aterrizar sin problemas. Por otro lado se usarón rieles que se obtuvieron previamente reutilizados, por lo cual la estacion de carga física se encuentra salida de la base de carga por unos 5 cm al momento de estar cerrada, pero en el diseño CAD el diseño si se encuentra cerrado por completo. 
        Imagen
        \item     Se añadió un espacio de 25 cm para colocar la parte electronica del cajón.
        imagen
    \end{itemize}



\subsection{Proceso de Manufactura de la Estructura de la Base de Carga}

    \begin{enumerate}
        \item \textbf{Corte del Material:} Para iniciar el proceso de manufactura, se realizaron cortes precisos de los perfiles de aluminio y las placas de MDF según las dimensiones especificadas en la lista de materiales. Este paso es fundamental para asegurar que todas las piezas se ensamblen correctamente en el diseño modular.
            \begin{center}
                \textit{Imagen del proceso de corte de perfiles de aluminio y MDF}
            \end{center}
        \item \textbf{Ensamblaje de la Estructura:} Una vez cortadas las piezas, se procedió a ensamblar la estructura principal de la estación de carga utilizando tornillos y tuercas para fijar los perfiles de aluminio y las placas de MDF usando los separadores impresos. Se verificó que todas las piezas estuvieran alineadas y niveladas para garantizar la estabilidad y resistencia de la base de carga.
            \begin{center}
                \textit{Imagen del proceso de ensamblaje de la estructura de la base de carga}
            \end{center}
        \item \textbf{Instalación del Mecanismo de Movimiento:} Después de ensamblar la estructura principal, se instaló el mecanismo de polea y banda tipo V para permitir el movimiento horizontal del cajón. Se colocaron las poleas, la banda y el motor en las ubicaciones previamente definidas, asegurando que el sistema de movimiento funcionara correctamente y sin obstrucciones.
            \begin{center}
                \textit{Imagen del proceso de instalación del mecanismo de movimiento}
            \end{center}
        
    \end{enumerate}



\subsection{Circuito Electrónico de la Estación de Carga}

    \subsubsection{Diagrama de Conexiones}
    Añadir diagrama de conexiones

    \subsubsection{Contrucción del Circuito}
    Añadir imágenes de la construcción del circuito

    \subsubsection{Programación del Circuito}
    Explicar el código de programación del circuito y su funcionamiento, mencionar que en los anexos se encuentra el código fuente del arduino y raspberry pi 4.


\section{Instrumentación del Dron}

\subsection{Especificaciones y Requerimientos}
Para garantizar la compatibilidad y funcionalidad en el sistema de carga, el dron debe cumplir con las siguientes especificaciones:
    \begin{itemize}
        \item Las dimensiones de las piezas deberán adaptarse al frame del drone cuadricoptero de arquitectura abierta que fue comprado.
        \item El dron deberá tener un circuito de carga compatible con la estacion de carga.
        \item El drone deberá contar con una cámara y un sistema de visión para la detección de marcadores Aruco.
        \item Se deberán integrar sensores de localización para la navegación en exterior.
        \item Se deberá integrar algún microprocesador como computadora auxiliar para el procesamiento de datos y la comunicación con la estación de carga.
    \end{itemize}

\subsection{Lista de Materiales para la Instrumentación del Dron} 
    \begin{itemize} 
        \item 1 x Frame de cuadricóptero abierto (especificar modelo) 
        \item 1 x Controlador de vuelo (especificar modelo) 
        \item 1 x Cámara (compatible con detección Aruco) 
        \item 1 x Raspberry Pi 4 (Companion Computer) 
        \item 1 x Sensor de proximidad (modelo de preferencia) 
        \item 1 x Módulo GPS (compatible con el controlador de vuelo) 
        \item Cableado y conectores 
        \item Material de montaje impreso en 3D (soportes específicos para cada componente) 
    \end{itemize}

\subsection{Diseños CAD del Dron} 
Se presentan a continuación los diseños CAD de las piezas que se han desarrollado para el dron, adaptadas a su frame original para integrar los componentes electrónicos necesarios y cumplir con los requisitos de carga y posicionamiento.

    \begin{itemize} 
        \item Se diseñaron nuevos soportes para el microprocesador y la cámara, asegurando una integración estable y precisa en el frame. 
        \item Se implementó un espacio de montaje para los sensores de localización y el circuito de carga. 
        \begin{center} 
            \textit{Imagen de los diseños CAD del dron con las piezas modificadas} 
        \end{center} 
    \end{itemize}



\subsection{Circuito de Distribución de Energía} 
El circuito de distribución de energía proporciona alimentación segura y estable a los componentes del dron. La selección de baterías y reguladores de voltaje fue optimizada para asegurar la duración de vuelo y protección de cada componente.

    \begin{itemize} 
        \item Se seleccionaron baterías de litio-polímero (LiPo) de alta capacidad para maximizar la autonomía. 
        \item Reguladores de voltaje se añadieron para adaptar el suministro a la Raspberry Pi, la cámara y el controlador de vuelo. 
        \begin{center} 
            \textit{Imagen del circuito de distribución de energía en el dron} 
        \end{center} 
    \end{itemize}

    \subsubsection{Integración de Componentes Electrónicos} Cada componente fue ensamblado y cableado de acuerdo con el diseño modular del dron. A continuación se describen los pasos del proceso de integración:

    \begin{enumerate} 
        \item \textbf{Montaje de la Cámara:} La cámara se fijó en la parte de abajo del dron, permitiendo una visibilidad óptima para la detección de marcadores Aruco. 
            \begin{center} 
                \textit{Imagen del montaje de la cámara en el dron} 
            \end{center} 
        \item \textbf{Instalación del Controlador de Vuelo y Módulo GPS:} El controlador de vuelo se instaló en el centro del frame para optimizar el balance y calibración, y el módulo GPS se colocó en una de las patas. 
            \begin{center} 
                \textit{Imagen del montaje del controlador de vuelo y módulo GPS} 
            \end{center} 
        \item \textbf{Instalación del Microprocesador:} La Raspberry Pi 4 se integró en un soporte impreso en 3D en la parte superior, y el microprocesador se colocó sobre este soporte. Un cable de comunicación serial se conectó entre la Raspberry Pi y el controlador de vuelo que se encuentra debajo de el microprocesador.
            \begin{center} 
                \textit{Imagen del montaje del microprocesador en el dron} 
            \end{center} 
    \end{enumerate}

\section{Software Configuration}

\subsection{Configuración de la Computadora Central en Tierra} 
La computadora central se configuró para supervisar y procesar la información proveniente de la computadora auxiliar del dron. A continuación, se describen los pasos realizados para esta configuración:

\begin{itemize}
    \item \textbf{Instalación de ROS 2 Humble:} 
    Dado que la computadora central utiliza Ubuntu 22.04, se instaló ROS 2 Humble siguiendo las instrucciones oficiales. Los comandos utilizados fueron:
    \begin{verbatim}
    sudo apt update && sudo apt install -y software-properties-common
    sudo add-apt-repository universe
    sudo apt update
    sudo apt install -y ros-humble-desktop
    \end{verbatim}
    Esto incluyó la instalación de las herramientas necesarias para desarrollar y ejecutar aplicaciones en ROS 2 Humble.

    \item \textbf{Configuración del entorno:} 
    Para facilitar el uso de ROS 2, se configuró el archivo \texttt{~/.bashrc}. Se agregó la siguiente línea al final del archivo:
    \begin{verbatim}
    source /opt/ros/humble/setup.bash
    \end{verbatim}
    Posteriormente, se ejecutó:
    \begin{verbatim}
    source ~/.bashrc
    \end{verbatim}

    \item \textbf{Clonación del repositorio de GitHub:} 
    Se creó un espacio de trabajo para ROS 2 y se clonó el repositorio correspondiente. Los pasos realizados fueron:
    \begin{verbatim}
    mkdir -p ~/ros2_ws/src
    cd ~/ros2_ws/src
    git clone <URL_del_repositorio>
    cd ..
    colcon build
    \end{verbatim}

    \item \textbf{Configuración del \texttt{ROS\_DOMAIN\_ID}:} 
    Para garantizar una correcta comunicación entre la computadora central y la computadora auxiliar del dron, se configuró el \texttt{ROS\_DOMAIN\_ID} con el valor 10. Esto se realizó añadiendo la siguiente línea al archivo \texttt{~/.bashrc}:
    \begin{verbatim}
    export ROS_DOMAIN_ID=10
    \end{verbatim}
    Luego, se ejecutó:
    \begin{verbatim}
    source ~/.bashrc
    \end{verbatim}
    
    \item \textbf{Verificación del entorno de ROS 2:} 
    Finalmente, se verificó que el entorno estuviera correctamente configurado utilizando los siguientes comandos:
    \begin{verbatim}
    ros2 doctor
    \end{verbatim}
    Esto permitió confirmar que todas las dependencias necesarias para ROS 2 Humble estuvieran instaladas y funcionando correctamente.
    
    \begin{center} 
        \textit{Imagen de la configuración del entorno en la computadora central.} 
    \end{center}
\end{itemize}


\subsection{Configuración de la Computadora Auxiliar del Dron} 
    La Raspberry Pi 5 se configuró como computadora auxiliar para el procesamiento de datos y comunicación en tiempo real con la estación de carga. A continuación, se detallan los pasos realizados para su configuración:
    
    \begin{itemize}
        \item \textbf{Instalación de Ubuntu 24.04:} 
        Se utilizó la herramienta Raspberry Pi Imager para instalar Ubuntu Server 24.04 LTS (64-Bit) en la tarjeta SD. Durante la configuración inicial, se habilitó SSH, se definió un usuario con contraseña y se conectó la Raspberry Pi a la red WiFi.
    
        \item \textbf{Conexión inicial y SSH:} 
        Después de insertar la tarjeta SD en la Raspberry Pi y conectarla a un monitor y teclado, se encendió el dispositivo e ingresaron las credenciales configuradas. Se obtuvo la dirección IP mediante el comando:
        \begin{verbatim}
        hostname -I
        \end{verbatim}
        Con esta información, se estableció una conexión SSH desde una computadora externa utilizando:
        \begin{verbatim}
        ssh <usuario>@<IP>
        \end{verbatim}
        Esto permitió continuar con la configuración de la Raspberry Pi de forma remota.
    
        \item \textbf{Actualización del sistema:} 
        Se realizó una actualización completa del sistema operativo con los siguientes comandos:
        \begin{verbatim}
        sudo apt update && sudo apt upgrade -y
        \end{verbatim}
        También se instaló \texttt{raspi-config} para habilitar el puerto serial. Esta opción se configuró en \texttt{Interface Options > Serial Port}, seleccionando \texttt{No} y luego \texttt{Yes}.
    
        \item \textbf{Modificación de \texttt{bashrc} y configuración del ID:} 
        Para garantizar la comunicación entre todos los dispositivos, se configuró el \texttt{ROS\_DOMAIN\_ID} con el valor 10. Se editó el archivo \texttt{~/.bashrc} con:
        \begin{verbatim}
        sudo vim ~/.bashrc
        \end{verbatim}
        Al final del archivo, se agregaron las siguientes líneas:
        \begin{verbatim}
        export ROS_DOMAIN_ID=10
        source /opt/ros/jazzy/setup.bash
        \end{verbatim}
        Posteriormente, se guardaron los cambios y se ejecutó:
        \begin{verbatim}
        source ~/.bashrc
        \end{verbatim}
    
        \item \textbf{Instalación de ROS 2 Jazzy:} 
        Se siguieron las instrucciones oficiales para instalar ROS 2 Jazzy en Ubuntu 24.04. Esto incluyó los comandos:
        \begin{verbatim}
        sudo apt install -y software-properties-common
        sudo add-apt-repository universe
        sudo apt update
        sudo apt install -y ros-jazzy-desktop
        \end{verbatim}
    
        \item \textbf{Clonación del repositorio de GitHub:} 
        Se creó un espacio de trabajo en ROS 2 para integrar los nodos personalizados. Los pasos realizados fueron:
        \begin{verbatim}
        mkdir -p ~/ros2_ws/src
        cd ~/ros2_ws/src
        git clone <URL_del_repositorio>
        cd ..
        colcon build
        \end{verbatim}
    
        \item \textbf{Instalación de MAVROS y MAVProxy:} 
        Para la comunicación con el Pixhawk, se instalaron MAVROS y MAVProxy. Los comandos utilizados fueron:
        \begin{verbatim}
        sudo apt install ros-jazzy-mavros ros-jazzy-mavros-extras
        sudo rosdep init
        rosdep update
        sudo apt install python3-mavproxy
        \end{verbatim}
        Además, se configuraron los complementos geográficos necesarios:
        \begin{verbatim}
        sudo apt install geographiclib-tools
        sudo geographiclib-get-geoids egm96-5
        \end{verbatim}
    
        \item \textbf{Verificación de la comunicación:} 
        Para garantizar que MAVROS y MAVProxy funcionaran correctamente, primero se inició MAVProxy con:
        \begin{verbatim}
        mavproxy.py --master=/dev/ttyAMA0 --baudrate 921600
        \end{verbatim}
        Posteriormente, se lanzó MAVROS utilizando:
        \begin{verbatim}
        ros2 launch mavros px4.launch fcu_url:=serial:///dev/ttyAMA0:921600
        \end{verbatim}
        Finalmente, se verificaron los tópicos disponibles con:
        \begin{verbatim}
        ros2 topic list
        \end{verbatim}
        y se confirmó la comunicación observando los mensajes de los tópicos relevantes.
        
        \begin{center} 
            \textit{Imagen de la configuración del entorno en la Raspberry Pi 5.} 
        \end{center}
    \end{itemize}
    
\subsection{Configuración de la Estación de Control en Tierra} 
    Se detalla la configuración realizada para la estación de control en tierra utilizando las herramientas QGroundControl y Mission Planner. Ambas aplicaciones son similares en funcionalidad, permitiendo la visualización y gestión de parámetros de vuelo. Sin embargo, dado que se utilizó ArduPilot como firmware, se decidió priorizar Mission Planner debido a su optimización para este sistema.
    
    \begin{itemize}
        \item \textbf{Instalación de Mission Planner y QGroundControl:} 
        Se instalaron ambas herramientas en la computadora central para la gestión y monitoreo del Pixhawk. Mission Planner se utilizó principalmente por su compatibilidad directa con ArduPilot, mientras que QGroundControl fue útil en ciertas configuraciones iniciales como algunas calibraciones redundates.
    
        \item \textbf{Calibración de sensores:} 
        La calibración de los sensores del Pixhawk que se realizó desde Mission Planner, siguiendo estos pasos:
        \begin{itemize}
            \item Acceder a la sección de calibración en la pestaña \textit{Initial Setup}.
            \item Seleccionar la opción de calibración para cada sensor:
            \begin{itemize}
                \item \textbf{Acelerómetro:} Se colocó el Pixhawk en diferentes orientaciones según las instrucciones en pantalla para calibrar correctamente.
                \item \textbf{Giroscopio:} Se mantuvo el Pixhawk inmóvil durante el proceso de calibración.
                \item \textbf{GPS:} Se verificó la recepción de satélites y se ajustaron los parámetros necesarios para una correcta ubicación.
            \end{itemize}
        \end{itemize}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{pictures/mp_calibration.png}
            \caption{Imagen de la configuración de sensores en Mission Planner.}
        \end{figure}

        
        \item \textbf{Parámetros de comunicación:} 
        Para establecer la comunicación entre la Raspberry Pi y el Pixhawk a través de MAVROS y MAVLink, se realizaron los siguientes ajustes en los parámetros utilizando Mission Planner:
        \begin{itemize}
            \item \texttt{SERIAL2\_PROTOCOL}: Configurado en 2 para habilitar MAVLink.
            \item \texttt{SERIAL2\_BAUD}: Ajustado a 921600 para coincidir con la configuración de la Raspberry Pi.
            \item \texttt{SYS\_ID}: Configurado en el ID correspondiente para garantizar una comunicación adecuada con el sistema.
        \end{itemize}
    
    \end{itemize}
    

\section{Sistema de Visión}
\subsection{Especificaciones y Requerimientos} 
El sistema de visión debe cumplir con los siguientes requisitos para garantizar la detección precisa de marcadores Aruco:
    \begin{itemize}
        \item Obtener las matrices de calibración intrínsecas y extrínsecas de la cámara.
        \item Generar y detectar marcadores Aruco de distintos tamaños en tiempo real.
    \end{itemize}

\subsection{Calibración de la Cámara} 
El proceso de calibración de la cámara se realizó utilizando un script en Python con la biblioteca OpenCV. Este procedimiento se detalla a continuación, combinando fragmentos del código y las imágenes obtenidas en cada etapa. El código completo se encuentra en los anexos del documento.
    
    \begin{enumerate}
        \item \textbf{Captura de imágenes:} 
        Se recopilaron múltiples imágenes del tablero de ajedrez desde diferentes ángulos y distancias para abarcar todo el campo de visión de la cámara. Estas imágenes presentaban distorsiones propias de la lente, como se observa en la Figura \ref{fig:imagen_descalibrada}.

        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/imagen_descalibrada.png}
                \caption{Ejemplo de imagen descalibrada tomada durante el proceso de captura.}
                \label{fig:imagen_descalibrada}
            \end{figure}
        \end{center}
    
        \item \textbf{Detección de esquinas:} 
        El script detectó las esquinas internas del tablero de ajedrez mediante la función \texttt{cv2.findChessboardCorners}. Posteriormente, se refinaron las esquinas detectadas utilizando \texttt{cv2.cornerSubPix}, y se visualizaron las líneas superpuestas en las imágenes de calibración, como se muestra en la Figura \ref{fig:det_ejemplos}.
        \begin{verbatim}
        ret, corners = cv2.findChessboardCorners(gray, (ncols, nrows), None)
        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.8\textwidth]{pictures/calib_predictions.png}
                \caption{Detección y refinamiento de esquinas en el tablero de ajedrez.}
                \label{fig:det_ejemplos}
            \end{figure}
        \end{center}
    
        \item \textbf{Calibración de la cámara:} 
        Utilizando \texttt{cv2.calibrateCamera}, se calcularon los parámetros intrínsecos de la cámara y los coeficientes de distorsión. Estos parámetros permiten corregir las distorsiones en las imágenes capturadas. La Figura \ref{fig:imagen_calibrada} muestra el resultado después de aplicar estos parámetros.
        \begin{verbatim}
        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, 
                                                           imgpoints, 
                                                           img_size, 
                                                           None, 
                                                           None)
        \end{verbatim}
        Donde:
        \begin{itemize}
            \item \texttt{mtx}: Matriz intrínseca de la cámara.
            \item \texttt{dist}: Coeficientes de distorsión.
            \item \texttt{rvecs}, \texttt{tvecs}: Rotaciones y traslaciones.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/imagen_calibrada.png}
                \caption{Imagen calibrada después de aplicar los parámetros obtenidos.}
                \label{fig:imagen_calibrada}
            \end{figure}
        \end{center}
    
        \item \textbf{Cálculo del error de calibración:} 
        Se verificó la precisión del modelo calculando el error promedio mediante \texttt{cv2.projectPoints}. Este cálculo compara las esquinas detectadas y proyectadas.
        \begin{verbatim}
        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)
        print("Total error: {}".format(mean_error / len(objpoints)))
        \end{verbatim}
    
        \item \textbf{Almacenamiento de parámetros:} 
        Los parámetros de calibración obtenidos se guardaron en un archivo JSON, lo que permite su reutilización en futuros procesos de corrección de imágenes.
        \begin{verbatim}
        data = {"camera_matrix": mtx.tolist(), 
                "distortion_coefficients": dist.tolist()}
        with open(output_path, "w") as file:
            json.dump(data, file, indent=4)
        \end{verbatim}
    \end{enumerate}
    
    
\subsection{Generación de Marcadores ArUco} 
    Se generaron marcadores ArUco adaptados al sistema, incluyendo tamaños y patrones específicos. En particular, se crearon marcadores embebidos, donde un marcador interno se incrusta dentro de un marcador externo para maximizar la precisión en la detección. A continuación, se describe el proceso paso a paso, destacando las partes importantes del código utilizado. El código completo se encuentra en los anexos del documento.
    
    \begin{enumerate}
        \item \textbf{Carga del diccionario de ArUco:} 
        Se utilizó el diccionario predefinido \texttt{DICT\_6X6\_250} de OpenCV, adecuado para generar marcadores con diferentes patrones y niveles de detalle.
        \begin{verbatim}
        aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_6X6_250)
        \end{verbatim}
    
        \item \textbf{Generación del marcador externo:} 
        Se definió un tamaño de 220 píxeles para el marcador externo (\texttt{outer\_marker\_size}) y se generó el marcador con un ID específico (\texttt{outer\_marker\_id}). Esto permitió crear un marcador grande que sirviera como contenedor.
        \begin{verbatim}
        outer_marker = aruco.generateImageMarker(aruco_dict, 
                                                 outer_marker_id, 
                                                 outer_marker_size)
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.4\textwidth]{pictures/aruco_marker_5.png}
                \caption{Marcador ArUco externo generado.}
            \end{figure}
        \end{center}
    
        \item \textbf{Generación del marcador interno:} 
        El marcador interno se generó con un tamaño de 50 píxeles (\texttt{inner\_marker\_size}) y un ID específico (\texttt{inner\_marker\_id}). Este marcador se diseñó para ser incrustado dentro del marcador externo.
        \begin{verbatim}
        inner_marker = aruco.generateImageMarker(aruco_dict, 
                                                 inner_marker_id, 
                                                 inner_marker_size)
        \end{verbatim}

        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.2\textwidth]{pictures/aruco_marker_100.png}
                \caption{Marcador interno con borde blanco añadido.}
            \end{figure}
        \end{center}
    
        \item \textbf{Creación del borde blanco alrededor del marcador interno:} 
        Se añadió un borde blanco de un píxel alrededor del marcador interno utilizando \texttt{cv2.copyMakeBorder}, lo que facilita su incrustación y aumenta la visibilidad en diferentes condiciones de iluminación.
        \begin{verbatim}
        inner_marker_with_border = cv2.copyMakeBorder(
            inner_marker,
            top=border_size,
            bottom=border_size,
            left=border_size,
            right=border_size,
            borderType=cv2.BORDER_CONSTANT,
            value=255  # Blanco
        )
        \end{verbatim}
        
    
        \item \textbf{Incrustación del marcador interno en el marcador externo:} 
        Se calculó la posición central para incrustar el marcador interno con borde en el marcador externo. El marcador externo se modificó para incluir un fondo negro en el centro antes de insertar el marcador interno con borde.
        \begin{verbatim}
        center_position = (outer_marker_size - inner_marker_with_border_size) // 2
        e_aruco_marker[center_position:center_position + inner_marker_with_border_size,
                       center_position:center_position + inner_marker_with_border_size] = 0
        e_aruco_marker[center_position:center_position + inner_marker_with_border_size,
                       center_position:center_position + inner_marker_with_border_size] = inner_marker_with_border
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.4\textwidth]{pictures/embedded_aruco.png}
                \caption{Marcador ArUco embebido generado.}
            \end{figure}
        \end{center}
    
        \item \textbf{Almacenamiento del marcador embebido:} 
        Finalmente, el marcador generado se guardó como una imagen PNG para su uso posterior.
        \begin{verbatim}
        cv2.imwrite(f'embedded_aruco_marker_{outer_marker_id}_{inner_marker_id}.png', 
                    e_aruco_marker)
        \end{verbatim}
    \end{enumerate}


\subsection{Detección de Marcadores e-Aruco en Tiempo Real} 
    El sistema fue diseñado para detectar marcadores Aruco en tiempo real, utilizando imágenes capturadas por una cámara conectada al dron. Este proceso se llevó a cabo mediante un nodo en ROS2 que procesa las imágenes y estima la pose de los marcadores con respecto a la cámara. El código completo se encuentra en los anexos del documento. A continuación, se describe el paso a paso del sistema:
    
    \begin{enumerate}
        \item \textbf{Publicación de imágenes desde el dron:} 
        La computadora auxiliar en el dron (companion computer) publica imágenes comprimidas capturadas por la cámara a un tópico de ROS 2 (\texttt{/camera\_image/compressed}). Estas imágenes se envían a la computadora en tierra para su procesamiento.
    
        \item \textbf{Recepción de imágenes en la computadora en tierra:} 
        Un nodo en la computadora en tierra se suscribe a las imágenes publicadas por el dron y realiza las siguientes tareas:
        \begin{itemize}
            \item Convierte las imágenes comprimidas en matrices utilizables para el procesamiento con OpenCV.
            \item Redimensiona las imágenes y las convierte a escala de grises para optimizar la detección.
        \end{itemize}
    
        \item \textbf{Detección de marcadores Aruco:} 
        Se utiliza la biblioteca OpenCV para detectar los marcadores Aruco presentes en la imagen. Los pasos incluyen:
        \begin{itemize}
            \item Uso del diccionario \texttt{DICT\_6X6\_250} para identificar marcadores específicos.
            \item Cálculo de las esquinas de los marcadores detectados mediante \texttt{aruco.detectMarkers}.
            \item Dibujo de los marcadores detectados para su visualización.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/deteccion_arucos.png}
                \caption{Detección de marcadores Aruco en la imagen procesada.}
            \end{figure}
        \end{center}
    
        \item \textbf{Estimación de la pose:} 
        Para cada marcador detectado, se calculó su posición y orientación en el espacio con respecto a la cámara. Esto se realizó utilizando la función \texttt{aruco.estimatePoseSingleMarkers}, que devuelve:
        \begin{itemize}
            \item \texttt{tvec}: Vector de traslación (\textit{x}, \textit{y}, \textit{z}) en metros.
            \item \texttt{rvec}: Vector de rotación que se convierte en ángulos de Euler (\textit{roll}, \textit{pitch}, \textit{yaw}) mediante matrices de rotación.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/calculo_pose.png}
                \caption{Representación gráfica de la posición y orientación calculada de un marcador Aruco.}
            \end{figure}
        \end{center}
    
        \item \textbf{Visualización y publicación de resultados:} 
        Los resultados obtenidos, incluyendo la pose de los marcadores, se visualizaron en tiempo real y se publicaron en un nuevo tópico de ROS 2 (\texttt{/aruco\_detection/compressed}). Las imágenes procesadas contenían:
        \begin{itemize}
            \item Marcadores detectados con esquinas resaltadas.
            \item Ejes X, Y y Z proyectados para mostrar la orientación de cada marcador.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/marcadores_ejes.png}
                \caption{Imagen con marcadores detectados y ejes proyectados.}
            \end{figure}
        \end{center}
    
        \item \textbf{Correcciones de posición:} 
        Basándose en los valores de \texttt{tvec}, se calcularon las correcciones necesarias para ajustar la posición del dron con respecto al marcador, incluyendo movimientos laterales (\textit{x}), verticales (\textit{y}) y de profundidad (\textit{z}).
    
        \item \textbf{Interacción con el sistema:} 
        Los resultados de la detección de marcadores Aruco se utilizaron para visualizar la posición y orientación del drone en tiempo real, lo que permitirá posteriormente que el sistema de control pueda ajustar las mismas para su aterrizaje en la estación de carga.
    \end{enumerate}
    

\section{Sistema de Comunicación}

    \subsection{Especificaciones y Requerimientos} 
    El sistema de comunicación entre el dron y la estación de carga fue diseñado para garantizar la transferencia eficiente y en tiempo real de datos críticos. Los requisitos principales son:
    
    \begin{itemize}
        \item \textbf{Red local basada en WiFi:} 
        Proporcionar una comunicación efectiva entre los dispositivos sin necesidad de acceso a Internet.
        \item \textbf{Middleware DDS de ROS 2:} 
        Utilizar la arquitectura de nodos y tópicos de ROS 2 para gestionar la comunicación de datos entre los dispositivos conectados.
    \end{itemize}
    
    \subsection{Estructura de Comunicación} 
    
    \subsubsection{Red Local WiFi} 
    La red local fue creada utilizando un router WiFi que conecta todos los dispositivos involucrados en el sistema, incluyendo el dron, la estación de carga y la computadora en tierra. Esta configuración eliminó la necesidad de Internet, proporcionando un entorno seguro y aislado para la transmisión de datos. El dron, equipado con una computadora auxiliar, transmitió datos mediante tópicos de ROS 2, como imágenes comprimidas y mensajes de estado, hacia la estación de carga y la computadora en tierra.
    
    \begin{figure}
        \centering
        %\includegraphics[width=0.8\textwidth]{pictures/wifi_network.png}
        \caption{Diagrama de la red local WiFi utilizada en el sistema.}
    \end{figure}
    
    \subsubsection{Comunicación mediante ROS 2} 
    El sistema utilizó la arquitectura de nodos y tópicos de ROS 2 para gestionar la comunicación entre los dispositivos. Cada dispositivo en la red cumplió funciones específicas relacionadas con la publicación y suscripción de datos relevantes:
    
    \begin{itemize}
        \item \textbf{Dron:} 
        Publicó imágenes de la cámara (\texttt{/camera\_image/compressed}) y datos de estado relacionados con la batería, posición y otros parámetros críticos.
        \item \textbf{Computadora en tierra:} 
        Contiene una interfaz que se suscribió a los tópicos publicados por el dron para:
        \begin{itemize}
            \item Procesar imágenes y calcular la posición de los marcadores Aruco.
            \item Mostrar datos de estado del dron, como nivel de batería y modo de vuelo, etc. en tiempo real.
            \item Publicar comandos hacia la estación de carga, como abrir o retraer el cajón de la estación, mediante tópicos específicos.
        \end{itemize}
        \item \textbf{Estación de carga:} 
        Se suscribió a los comandos enviados desde la interfaz de la computadora en tierra para ejecutar las acciones necesarias, como la apertura y cierre del cajón.
    \end{itemize}
    
    \begin{figure}
        \centering
        %\includegraphics[width=0.8\textwidth]{pictures/ros2_comms.png}
        \caption{Diagrama de comunicación entre los dispositivos utilizando ROS 2.}
    \end{figure}
    

    




