% Desarrollo

This chapter describes the process of design, implementation and configuration of the modular charging station and drone instrumentation. It details the methodologies and tools used to carry out the development, with a focus on creating an effective solution for the charging system.
\section{Charging Station Design and Development}

\subsection{Requirements}
    The following are the technical specifications and requirements for the charging station, ensuring compatibility and efficiency for a drone swarm charging system:     
       \begin{enumerate}
            \item The system shall have a design that is modular and stackable for integration of multiple charging stations. 
            \item The system shall take into account and adapt to the dimensions of the drone proposed for the application.
            \item The system shall have an automatic opening and closing mechanism for the storage drawer of the drone.
            \item The system shall have a charging mechanism for the drone battery.
            \item The system shall contain vision positioning method for the drone.
        \end{enumerate}

\subsection{Materials List}
The following is the materials list used for the construction of the modular charging station. It should be noted that the design and development of this project were largely based on previously available resources and materials, which allowed cost optimization and efficient use of existing inputs.    \begin{itemize}
        \item Aluminum Profiles
            \begin{itemize}
                \item \textbf{30 mm:}
                \begin{itemize}
                \item 4 x Profiles de 100 mm
                \item 4 x Profiles de 810 mm
                \item 6 x Profiles de 750 mm
                \end{itemize}
                \item \textbf{40 mm:}
                \begin{itemize}
                \item 2 x Profiles de 1040 mm
                \item 4 x Profiles de 560 mm
                \item 4 x Profiles de 830 mm
                \item 4 x Profiles de 1120 mm
                \end{itemize}
            \end{itemize}
            \item 16 x 3D printed aluminum profile frames
            \item Aluminum profile turning machine
            \item 2 x Telescopic Correction Riel
            \item 1 x 12V motor
            \item 1 x 3D printed motor brackets
            \item 1 x A V-Belts 1 m 
            \item 2 x Pole type A with internal diameter of 1/2”
            \item 2 x DI Bearing: 15 mm y DE: 35 mm
            \item 2 x 3D printed bearings
            \item 2 x 9 mm MDF 75x75 cm
            \item 8 x 3D printed MDF dividers
            \item 1 x 12V power supply
            \item 1 x Arduino Mega
            \item 1 x Raspberry Pi 4
            \item 1 x H Bridge BTS7960 
            \item 2 x Inductive Proximity Sensor
            \item 1 x Joystick
            \item 1 x WiFi Router
            \item 1 x BT3 Pro Compact Charger
            \item 1 X Cable Carrier 1 m
    \end{itemize}

\subsection{CAD Design of the Charging Base}

To meet the requirements of modular / stackable design and compatibility with the drone in question to the dimensions of the drone. The following CAD design was carried out:
As shown in \ref{fig:etiqueta1} The base known as the “inner drawer” was designed to serve as a platform for takeoff and landing of the drone. This design was made considering the dimensions of the drone and ensuring the inclusion of adequate tolerances to prevent possible collisions. A 30 mm aluminum profile was used in this design, taking advantage of the fact that this material was already available. Other profiles were also integrated in the middle of the box and horizontally, which would support the rails.           
 \begin{figure}[htpb]
                \centering
                \includegraphics[width=0.8\textwidth]{pictures/PLANOS_CAJON_INTERNO_1.png}
                \caption{Drawing of the internal drawer of the Charging Station}
                \label{fig:etiqueta1}
            \end{figure}
            
            Therefore, taking into account the dimensions of the previous plan, the “external drawer” was made, which is used to store the drone and the electronics of the charging station. This can be seen in \ref{fig:etiqueta2}.           
            \begin{figure}[htpb]
                \centering
                \includegraphics[width=0.8\textwidth]{pictures/PLANOS_CAJON_EXTERNO_1.png}
                \caption{Drawing of the external drawer of the Charging Station}
                \label{fig:etiqueta2}
            \end{figure}

            Then, the dimensions of the landing gear (drone legs) were taken into account to make some mechanical guides (\ref{fig:etiqueta3}) that help them to make a correct magnetic connection with the charging system.            \begin{figure}[htpb]
                \centering
                \includegraphics[width=0.8\textwidth]{pictures/PLANO_GUIAS_MECANICAS.png}
                \caption{Mechanical Guidance Drawing for Charging Station}
                \label{fig:etiqueta3}
            \end{figure}


            The necessary CAD designs were developed as shown in \ref{fig:imagen1} and \ref{fig:imagen2} to ensure the correct integration and adaptation of the different components of the charging station. These designs made it possible to establish the essential dimensions, tolerances and features so that each element would fit precisely, ensuring that the charging station would fulfill its functionality efficiently and reliably.The necessary CAD designs were developed as shown in Fig 4. and Fig 5. to ensure the correct integration and adaptation of the different components of the charging station. These designs made it possible to establish the essential dimensions, tolerances and features so that each element would fit precisely, ensuring that the charging station would fulfill its functionality efficiently and reliably.
    \begin{figure}[h]
        \centering
        \begin{minipage}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{pictures/PLANO_PATAS_ESTABILIDAD_CAJON.png}
            \caption{Mechanical guide designed to ensure correct positioning of the drone, allowing the drone legs to be magnetically connected to the power supply system.}
            \label{fig:imagen1}
        \end{minipage}%
        \hfill
        \begin{minipage}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{pictures/PLANO_SENSOR.png}
            \caption{Image 2}
            \label{fig:imagen2}
        \end{minipage}%
        \hfill
    \end{figure}

\subsection{Selection and Implementation of Drawer Motion Mechanism}

Section 2.2.3 explains in detail the different motion mechanisms that were considered for the loading station, evaluating their advantages and disadvantages in terms of accuracy, durability, cost, and ease of integration into the modular design. Options such as linear pistons, toothed belts and other transmission systems were analyzed in order to select a solution that would meet the functionality requirements without increasing costs too much. Tras esta evaluación, se optó por un mecanismo de Polea y Banda tipo V, el cual, además de ser una opción económica, utiliza componentes ya disponibles, como el motor. Este sistema permite un movimiento horizontal suficiente para posicionar el dron con la precisión necesaria para el proceso de carga, a la vez que facilita el apilamiento modular de la estación. La orientación del movimiento no obstruye la estructura general de la estación, lo cual asegura que el diseño cumpla con el requisito de apilabilidad y compatibilidad en espacios compartidos, manteniéndose compacto y adaptable sin comprometer la estructura modular de la estación.

For this mechanism, different components were selected, including a high-strength belt, pulleys, and a DC motor with torque of 3.42 Nm. The belt should support the expected loads, the pulleys (with low friction) would optimize the movement and reduce the wear of the system in continuous operations, and the motor would pull the 3 kg weight of the drone plus the weight of the drawer.
    \subsubsection{CAD Designs y Components}
        \begin{enumerate}
            \item 12V motor
            \item Pole
            \item Band
            \item Baleros
            \item Bearings 
            \item Motor support
        \end{enumerate}

    \subsubsection{V-type Belt and Pulley Mechanism}
    (Mechanism Image)

    \subsection{CAD Design of the Charging Base}
    To meet the requirements of modular / stackable design and compatibility with the drone in question to the dimensions of the drone. The following CAD design was carried out:

        \begin{itemize}
            \item     The design of the main structure of the charging station was made in Fusion 360, considering the minimum dimensions required for the drone and the charging mechanism.
            Image
            \item     The necessary dimension was taken into account so that the drone has a space of at least 10 cm of separation with the wall of the box. This is to avoid any collusion of the drone with the structure of the cargo base when trying to land, also the height of the box was decreased so that the drone can land without problems. On the other hand, we used rails that were obtained previously reused, so the physical charging station is out of the charging base by about 5 cm at the time of being closed. However, in the CAD design, the design is completely closed. 
            Image
            \item     A space of 25 cm was added to place the electronic part of the drawer.
            image
        \end{itemize}



\subsection{Manufacturing Process of the Base Load Frame}

    \begin{enumerate}
        \item \textbf{Material Cutting:}  To start the manufacturing process, precise cuts of the aluminum profiles and MDF boards were made according to the dimensions specified in the materials list. This step is critical to ensure that all parts are assembled correctly in the modular design.
            \begin{center}
                \textit{Image of the cutting process of aluminum and MDF profiles}
            \end{center}
        \item \textbf{Structure Assembly:} Once the parts were cut, the main structure of the loading station was assembled using bolts and nuts to fix the aluminum profiles and the MDF plates using the printed spacers. All parts were checked to ensure that they were aligned and leveled to guarantee the stability and strength of the loading base.
        \begin{center}
                \textit{Image of the assembly process of the load-bearing base structure}
            \end{center}
        \item \textbf{Installation of the Motion Mechanism:} After the main structure was assembled, the V-type pulley and belt mechanism was installed to allow horizontal movement of the caisson. The pulleys, belt, and motor were placed in the previously defined locations, ensuring that the motion system would function properly and without obstructions.
        \begin{center}
                \textit{Image of the installation process of the movement mechanism}
            \end{center}
        
    \end{enumerate}


%%ANABI starts

    \subsection{Electronic Circuit of the Charging Station}

    \subsubsection{Conection Diagram}
    add diagram circuit
    
    \subsubsection{Circuit Construction}
    add images
    
    \subsubsection{Circuit Programming}
    
    \paragraph{\textbf{General Description:}}
    
    
    The described circuit uses a joystick to control a motor that moves a drawer back and forth. The joystick is connected to a microcontroller (Arduino Mega 2560), which reads the joystick's Y-axis values to determine the direction in which the motor should move. Depending on the position of the joystick, the motor moves forward, backward or stops. In addition, limit switches are used to ensure that the motor stops when the drawer reaches its extreme positions.
    
    
    
    \paragraph{\textbf{Main Components}
    }
    \begin{itemize}
        \item \textbf{Arduino:} Microcontroller that manages the reading of the joystick values and controls the motor.
        \item \textbf{Joystick:} Analog input device that allows the user to control the direction of movement.
        \item \textbf{Motor and H-Bridge:} Driver system that moves the drawer. The H-bridge allows controlling the direction and speed of motion of the motor.
        \item \textbf{Limit Switches:} Sensors that detect when the drawer has reached its extreme positions (forward and reverse).
        \item \textbf{Power Supply:} Supplies power to the motor. The Arduino and RaspberryPi4 are supplied power by a plug-in charger.
    \end{itemize}
    
    
    \paragraph{\textbf{Arduino Code}
    }
    
    The Arduino code performs the following functions:
    
    \begin{enumerate}
        \item \textbf{Pin initialization:}
        \begin{itemize}
            \item The joystick pins (A1 for the Y-axis) are configured as inputs.
            \item Motor pins 9 and 8 are configured as outputs.
            \item The limit switch pins (10 and 11) are configured as inputs with internal pull-up resistors.
        \end{itemize}
        \item \textbf{Reading of Joystick:}
        \begin{itemize}
            \item At each loop cycle, the Arduino reads the analog value from the joystick's Y-axis.
            \item Depending on the value read, the Arduino decides whether the motor should move forward, backward or stop.
        \end{itemize}
        \item \textbf{Motor Control:}
        \begin{itemize}
            \item If the value of the joystick Y-axis is greater than 512 (middle position) and the forward limit switch is not pressed, the motor moves forward.
            \item If the Y-axis value is less than 512 and the backward limit switch is not pressed, the motor moves backward.
            \item If the Y-axis value is approximately 512 or any limit switch is pressed, the motor stops.
        \end{itemize}
        \item \textbf{Limit Switch Verification:}
        \begin{itemize}
            \item If the motor is moving forward and the forward limit detects  metal (the drawer), the motor stops.
            \item If the motor is moving backward and the backward limit switch detects  metal (the drawer), the motor stops.
    
        \end{itemize}
        
    \end{enumerate}
    
    %%%%%CODIGOOOOOOOO (??????)
    
    \paragraph{\textbf{Circuit Operation}
    }
    \begin{itemize}
        \item Initialization: At startup, the Arduino configures the pins and establishes serial communication for debugging.
    \item Continuous Readout: In the main loop, the Arduino continuously reads the value of the joystick Y-axis.
    \item Dynamic Control: Based on the value read, the Arduino controls the motor to move the drawer forward, backward or stop it.
    \item Safety Check: Limit switches ensure that the motor automatically stops when the drawer reaches its extreme positions, protecting the system from possible damage.
    \item Debugging: Joystick values and motor status are printed on the serial monitor for easy debugging and system tuning.
    \end{itemize}
    
    \paragraph{\textbf{Annex}
    }
    \paragraph{
    The complete source code for both the Arduino and Raspberry Pi 4 is included in the appendices of this document, making it easy to review and modify as needed for implementation and control of the system.
    
    This approach ensures that the drawer moves in a precise and controlled manner based on the joystick position, providing an efficient solution for linear motion control using a motor and belt.}
    
%%ANABI ENDS
    







\section{Drone Instrumentation}

\subsection{Specifications and Requirements}
To ensure compatibility and functionality in the charging system, the drone must meet the following specifications:
    \begin{itemize}
        \item The dimensions of the parts must be adapted to the frame of the quadcopter drone of open architecture that was purchased.
        \item The drone must have a charging circuit compatible with the charging station.
        \item The drone must have a camera and a vision system for the detection of ArUco markers.
        \item Location sensors shall be integrated for outdoor navigation.
        \item A microprocessor should be integrated as an auxiliary computer for data processing and communication with the charging station.
    \end{itemize}

\subsection{Drone Instrumentation Materials List} 
    \begin{itemize} 
        \item 1 x Open quadcopter frame (F450) 
        \item 1 x Flight Controller (PIxHawk 6x) 
        \item 1 x Camera (compatible with ArUco detection) 
        \item 1 x Raspberry Pi 4 (Companion Computer) 
        \item 1 x Proximity Sensor (model of preference) 
        \item 1 x GPS Module (compatible with flight controller) 
        \item Wiring and connectors 
        \item 3D printed mounting hardware (specific brackets for each component) 
    \end{itemize}

\subsection{Drone CAD drawings} 
Presented below are the CAD designs of the parts that have been developed for the drone, adapted to its original frame to integrate the necessary electronic components and meet the loading and positioning requirements.
    \begin{itemize} 
        \item New brackets were designed for the microprocessor and camera, ensuring stable and precise integration into the frame. 
        \item A mounting space for the location sensors and charging circuitry was implemented. 
        \begin{center} 
            \textit{Image of the CAD designs of the drone with the modified parts.} 
        \end{center} 
    \end{itemize}

    \subsection{Power Distribution Circuit} 
    The power distribution circuit was designed to provide safe and stable power to the drone's critical components, including the motors, flight controller, Raspberry Pi 5, and camera. The operation of each section of the circuit is described below:
    
    \begin{enumerate}
        \item \textbf{3S LiPo battery:} 
        A 3-cell lithium-polymer (LiPo) battery with a capacity of 5200 mAh, a nominal voltage of 11.1 V and a discharge rate of 50 C was selected. This battery is ideal for providing the necessary current for the motors and electronics without compromising flight duration.

        \item \textbf{Power distribution to the motors:} 
        Power from the battery is distributed through a power distribution board, which connects the battery to the four electronic speed controllers (ESCs). Each ESC regulates the power sent to its respective A2212 10T motor, allowing precise speed control of the motors.
    
        \item \textbf{Voltage regulator XL4005 DC-DC:} 
        This regulator converts the 11.1 V battery voltage to 5 V, providing stable and safe power supply for the Raspberry Pi and the connected camera.
    
        \item \textbf{Flight controller Pixhawk 6X RT:} 
        The flight controller is connected directly to the power distribution board to receive the necessary power. It also manages communication with the ESCs and other sensors on the drone, such as the GPS module (M9N) connected to the GPS1 port.

        \item \textbf{Raspberry Pi 5:} 
        The Raspberry Pi is powered through the voltage regulator and connects to the flight controller via a serial port to receive data and send commands to the system. It also manages the USB-connected camera, which captures images for real-time processing.
    
        \item \textbf{GPS Module M9N:} 
        This module connects to the Pixhawk controller via the GPS1 port to provide real-time outdoor positioning data essential for drone navigation.
    
    \end{enumerate}
    
    \begin{center}
        \begin{figure}[h!]
            \centering
            \includegraphics[width=0.8\textwidth]{pictures/drone_electronic_diagram.png}
            \caption{Diagram of the power distribution circuit of the drone}.
        \end{figure}
    \end{center}
        

\section{Software Configuration}

\subsection{Ground Host Computer Configuration} 
The central computer was configured to monitor and process the information coming from the drone's auxiliary computer. The steps performed for this configuration are described below:
\begin{itemize}
    \item \textbf{Installation of ROS 2 Humble:} 
    Since the host computer is running Ubuntu 22.04, ROS 2 Humble was installed following the official instructions. The commands used were:    \begin{verbatim}
    sudo apt update && sudo apt install -y software-properties-common
    sudo add-apt-repository universe
    sudo apt update
    sudo apt install -y ros-humble-desktop
    \end{verbatim}
    This included the installation of the necessary tools to develop and run applications on ROS 2 Humble.

    \item \textbf{Configuración del entorno:} 
    To facilitate the use of ROS 2, the file \texttt{~/.bashrc} was configured. The following line was added to the end of the file:
        \begin{verbatim}
    source /opt/ros/humble/setup.bash
    \end{verbatim}
    It was subsequently executed:
    \begin{verbatim}
    source ~/.bashrc
    \end{verbatim}

    \item \textbf{GitHub repository cloning:} 
    A workspace was created for ROS 2 and the corresponding repository was cloned. The steps performed were:
    \begin{verbatim}
    mkdir -p ~/ros2_ws/src
    cd ~/ros2_ws/src
    git clone <URL_del_repositorio>
    cd ..
    colcon build
    \end{verbatim}

    \item \textbf{\texttt{ROS\_DOMAIN\_ID} Configuration:} 
    To ensure proper communication between the host computer and the drone's auxiliary computer, the \texttt{ROSAIN_ID} was configured with the value 10. This was done by adding the following line to the \texttt{~/.bashrc} file:    \begin{verbatim}
    export ROS_DOMAIN_ID=10
    \end{verbatim}
    It was then executed:    \begin{verbatim}
    source ~/.bashrc
    \end{verbatim}
    
    \item \textbf{ROS 2 environment Verification:} 
    Finally, the environment was verified to be correctly configured using the following commands:
    \begin{verbatim}
    ros2 doctor
    \end{verbatim}
    This allowed us to confirm that all the necessary dependencies for ROS 2 Humble were installed and working correctly.    
    \begin{center} 
        \textit{Image of the environment configuration on the main computer.} 
    \end{center}
\end{itemize}


\subsection{Configuration of the Drone Auxiliary Computer} 
The Raspberry Pi 5 was configured as an auxiliary computer for data processing and real-time communication with the charging station. The steps performed for its configuration are detailed below:

    \begin{itemize}
        \item \textbf{Installing Ubuntu 24.04:} 
        The Raspberry Pi Imager tool was used to install Ubuntu Server 24.04 LTS (64-Bit) on the SD card. During the initial setup, SSH was enabled, a user with password was defined and the Raspberry Pi was connected to the Wi-Fi network.
    
        \item \textbf{Initial connection and SSH:} 
        After inserting the SD card into the Raspberry Pi and connecting it to a monitor and keyboard, the device was powered on, and the configured credentials were entered. The IP address was obtained using the command:
        \begin{verbatim}
        hostname -I
        \end{verbatim}
        With this information, an SSH connection was established from an external computer using:        \begin{verbatim}
        ssh <usuario>@<IP>
        \end{verbatim}
        This allowed to continue with the configuration of the Raspberry Pi remotely.

        \item \textbf{System upgrade:} 
        A complete operating system upgrade was performed with the following commands:
        \begin{verbatim}
        sudo apt update && sudo apt upgrade -y
        \end{verbatim}
        \texttt{raspi-config} was also installed to enable the serial port. This option was configured in \texttt{Interface Options > Serial Port}, selecting \texttt{No} and then \texttt{Yes}.

        \item \textbf{Modification of \texttt{bashrc} and ID configuration:} 
        To ensure communication between all devices, the \texttt{ROSAIN_ID} was set to 10. The \texttt{~/.bashrc} file was edited with:        \begin{verbatim}
        sudo vim ~/.bashrc
        \end{verbatim}
        At the end of the file, the following lines were added:
                \begin{verbatim}
        export ROS_DOMAIN_ID=10
        source /opt/ros/jazzy/setup.bash
        \end{verbatim}
        Subsequently, the changes were saved and executed:
        \begin{verbatim}
        source ~/.bashrc
        \end{verbatim}
    
        \item \textbf{ROS 2 Jazzy Installation:} 
        Official instructions were followed to install ROS 2 Jazzy on Ubuntu 24.04. This included the commands:
                \begin{verbatim}
        sudo apt install -y software-properties-common
        sudo add-apt-repository universe
        sudo apt update
        sudo apt install -y ros-jazzy-desktop
        \end{verbatim}
    
        \item \textbf{GitHub repository cloning:} 
        A workspace was created in ROS 2 to integrate the custom nodes. The steps performed were:       
         \begin{verbatim}
        mkdir -p ~/ros2_ws/src
        cd ~/ros2_ws/src
        git clone <URL_del_repositorio>
        cd ..
        colcon build
        \end{verbatim}
    %%%anabi aqui
        \item \textbf{Instalación de MAVROS y MAVProxy:} 
        Para la comunicación con el Pixhawk, se instalaron MAVROS y MAVProxy. Los comandos utilizados fueron:
        \begin{verbatim}
        sudo apt install ros-jazzy-mavros ros-jazzy-mavros-extras
        sudo rosdep init
        rosdep update
        sudo apt install python3-mavproxy
        \end{verbatim}
        Además, se configuraron los complementos geográficos necesarios:
        \begin{verbatim}
        sudo apt install geographiclib-tools
        sudo geographiclib-get-geoids egm96-5
        \end{verbatim}
    
        \item \textbf{Verificación de la comunicación:} 
        Para garantizar que MAVROS y MAVProxy funcionaran correctamente, primero se inició MAVProxy con:
        \begin{verbatim}
        mavproxy.py --master=/dev/ttyAMA0 --baudrate 921600
        \end{verbatim}
        Posteriormente, se lanzó MAVROS utilizando:
        \begin{verbatim}
        ros2 launch mavros px4.launch fcu_url:=serial:///dev/ttyAMA0:921600
        \end{verbatim}
        Finalmente, se verificaron los tópicos disponibles con:
        \begin{verbatim}
        ros2 topic list
        \end{verbatim}
        y se confirmó la comunicación observando los mensajes de los tópicos relevantes.
        
        \begin{center} 
            \textit{Imagen de la configuración del entorno en la Raspberry Pi 5.} 
        \end{center}
    \end{itemize}
    
\subsection{Configuración de la Estación de Control en Tierra} 
    Se detalla la configuración realizada para la estación de control en tierra utilizando las herramientas QGroundControl y Mission Planner. Ambas aplicaciones son similares en funcionalidad, permitiendo la visualización y gestión de parámetros de vuelo. Sin embargo, dado que se utilizó ArduPilot como firmware, se decidió priorizar Mission Planner debido a su optimización para este sistema.
    
    \begin{itemize}
        \item \textbf{Instalación de Mission Planner y QGroundControl:} 
        Se instalaron ambas herramientas en la computadora central para la gestión y monitoreo del Pixhawk. Mission Planner se utilizó principalmente por su compatibilidad directa con ArduPilot, mientras que QGroundControl fue útil en ciertas configuraciones iniciales como algunas calibraciones redundates.
    
        \item \textbf{Calibración de sensores:} 
        La calibración de los sensores del Pixhawk que se realizó desde Mission Planner, siguiendo estos pasos:
        \begin{itemize}
            \item Acceder a la sección de calibración en la pestaña \textit{Initial Setup}.
            \item Seleccionar la opción de calibración para cada sensor:
            \begin{itemize}
                \item \textbf{Acelerómetro:} Se colocó el Pixhawk en diferentes orientaciones según las instrucciones en pantalla para calibrar correctamente.
                \item \textbf{Giroscopio:} Se mantuvo el Pixhawk inmóvil durante el proceso de calibración.
                \item \textbf{GPS:} Se verificó la recepción de satélites y se ajustaron los parámetros necesarios para una correcta ubicación.
            \end{itemize}
        \end{itemize}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{pictures/mp_calibration.png}
            \caption{Imagen de la configuración de sensores en Mission Planner.}
        \end{figure}

        
        \item \textbf{Parámetros de comunicación:} 
        Para establecer la comunicación entre la Raspberry Pi y el Pixhawk a través de MAVROS y MAVLink, se realizaron los siguientes ajustes en los parámetros utilizando Mission Planner:
        \begin{itemize}
            \item \texttt{SERIAL2\_PROTOCOL}: Configurado en 2 para habilitar MAVLink.
            \item \texttt{SERIAL2\_BAUD}: Ajustado a 921600 para coincidir con la configuración de la Raspberry Pi.
            \item \texttt{SYS\_ID}: Configurado en el ID correspondiente para garantizar una comunicación adecuada con el sistema.
        \end{itemize}
    
    \end{itemize}
    

\section{Sistema de Visión}
\subsection{Especificaciones y Requerimientos} 
El sistema de visión debe cumplir con los siguientes requisitos para garantizar la detección precisa de marcadores Aruco:
    \begin{itemize}
        \item Obtener las matrices de calibración intrínsecas y extrínsecas de la cámara.
        \item Generar y detectar marcadores Aruco de distintos tamaños en tiempo real.
    \end{itemize}

\subsection{Calibración de la Cámara} 
El proceso de calibración de la cámara se realizó utilizando un script en Python con la biblioteca OpenCV. Este procedimiento se detalla a continuación, combinando fragmentos del código y las imágenes obtenidas en cada etapa. El código completo se encuentra en los anexos del documento.
    
    \begin{enumerate}
        \item \textbf{Captura de imágenes:} 
        Se recopilaron múltiples imágenes del tablero de ajedrez desde diferentes ángulos y distancias para abarcar todo el campo de visión de la cámara. Estas imágenes presentaban distorsiones propias de la lente, como se observa en la Figura \ref{fig:imagen_descalibrada}.

        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/imagen_descalibrada.png}
                \caption{Ejemplo de imagen descalibrada tomada durante el proceso de captura.}
                \label{fig:imagen_descalibrada}
            \end{figure}
        \end{center}
    
        \item \textbf{Detección de esquinas:} 
        El script detectó las esquinas internas del tablero de ajedrez mediante la función \texttt{cv2.findChessboardCorners}. Posteriormente, se refinaron las esquinas detectadas utilizando \texttt{cv2.cornerSubPix}, y se visualizaron las líneas superpuestas en las imágenes de calibración, como se muestra en la Figura \ref{fig:det_ejemplos}.
        \begin{verbatim}
        ret, corners = cv2.findChessboardCorners(gray, (ncols, nrows), None)
        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.8\textwidth]{pictures/calib_predictions.png}
                \caption{Detección y refinamiento de esquinas en el tablero de ajedrez.}
                \label{fig:det_ejemplos}
            \end{figure}
        \end{center}
    
        \item \textbf{Calibración de la cámara:} 
        Utilizando \texttt{cv2.calibrateCamera}, se calcularon los parámetros intrínsecos de la cámara y los coeficientes de distorsión. Estos parámetros permiten corregir las distorsiones en las imágenes capturadas. La Figura \ref{fig:imagen_calibrada} muestra el resultado después de aplicar estos parámetros.
        \begin{verbatim}
        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, 
                                                           imgpoints, 
                                                           img_size, 
                                                           None, 
                                                           None)
        \end{verbatim}
        Donde:
        \begin{itemize}
            \item \texttt{mtx}: Matriz intrínseca de la cámara.
            \item \texttt{dist}: Coeficientes de distorsión.
            \item \texttt{rvecs}, \texttt{tvecs}: Rotaciones y traslaciones.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/imagen_calibrada.png}
                \caption{Imagen calibrada después de aplicar los parámetros obtenidos.}
                \label{fig:imagen_calibrada}
            \end{figure}
        \end{center}
    
        \item \textbf{Cálculo del error de calibración:} 
        Se verificó la precisión del modelo calculando el error promedio mediante \texttt{cv2.projectPoints}. Este cálculo compara las esquinas detectadas y proyectadas.
        \begin{verbatim}
        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)
        print("Total error: {}".format(mean_error / len(objpoints)))
        \end{verbatim}
    
        \item \textbf{Almacenamiento de parámetros:} 
        Los parámetros de calibración obtenidos se guardaron en un archivo JSON, lo que permite su reutilización en futuros procesos de corrección de imágenes.
        \begin{verbatim}
        data = {"camera_matrix": mtx.tolist(), 
                "distortion_coefficients": dist.tolist()}
        with open(output_path, "w") as file:
            json.dump(data, file, indent=4)
        \end{verbatim}
    \end{enumerate}
    
    
\subsection{Generación de Marcadores ArUco} 
    Se generaron marcadores ArUco adaptados al sistema, incluyendo tamaños y patrones específicos. En particular, se crearon marcadores embebidos, donde un marcador interno se incrusta dentro de un marcador externo para maximizar la precisión en la detección. A continuación, se describe el proceso paso a paso, destacando las partes importantes del código utilizado. El código completo se encuentra en los anexos del documento.
    
    \begin{enumerate}
        \item \textbf{Carga del diccionario de ArUco:} 
        Se utilizó el diccionario predefinido \texttt{DICT\_6X6\_250} de OpenCV, adecuado para generar marcadores con diferentes patrones y niveles de detalle.
        \begin{verbatim}
        aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_6X6_250)
        \end{verbatim}
    
        \item \textbf{Generación del marcador externo:} 
        Se definió un tamaño de 220 píxeles para el marcador externo (\texttt{outer\_marker\_size}) y se generó el marcador con un ID específico (\texttt{outer\_marker\_id}). Esto permitió crear un marcador grande que sirviera como contenedor.
        \begin{verbatim}
        outer_marker = aruco.generateImageMarker(aruco_dict, 
                                                 outer_marker_id, 
                                                 outer_marker_size)
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.4\textwidth]{pictures/aruco_marker_5.png}
                \caption{Marcador ArUco externo generado.}
            \end{figure}
        \end{center}
    
        \item \textbf{Generación del marcador interno:} 
        El marcador interno se generó con un tamaño de 50 píxeles (\texttt{inner\_marker\_size}) y un ID específico (\texttt{inner\_marker\_id}). Este marcador se diseñó para ser incrustado dentro del marcador externo.
        \begin{verbatim}
        inner_marker = aruco.generateImageMarker(aruco_dict, 
                                                 inner_marker_id, 
                                                 inner_marker_size)
        \end{verbatim}

        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.2\textwidth]{pictures/aruco_marker_100.png}
                \caption{Marcador interno con borde blanco añadido.}
            \end{figure}
        \end{center}
    
        \item \textbf{Creación del borde blanco alrededor del marcador interno:} 
        Se añadió un borde blanco de un píxel alrededor del marcador interno utilizando \texttt{cv2.copyMakeBorder}, lo que facilita su incrustación y aumenta la visibilidad en diferentes condiciones de iluminación.
        \begin{verbatim}
        inner_marker_with_border = cv2.copyMakeBorder(
            inner_marker,
            top=border_size,
            bottom=border_size,
            left=border_size,
            right=border_size,
            borderType=cv2.BORDER_CONSTANT,
            value=255  # Blanco
        )
        \end{verbatim}
        
    
        \item \textbf{Incrustación del marcador interno en el marcador externo:} 
        Se calculó la posición central para incrustar el marcador interno con borde en el marcador externo. El marcador externo se modificó para incluir un fondo negro en el centro antes de insertar el marcador interno con borde.
        \begin{verbatim}
        center_position = (outer_marker_size - inner_marker_with_border_size) // 2
        e_aruco_marker[center_position:center_position + inner_marker_with_border_size,
                       center_position:center_position + inner_marker_with_border_size] = 0
        e_aruco_marker[center_position:center_position + inner_marker_with_border_size,
                       center_position:center_position + inner_marker_with_border_size] = inner_marker_with_border
        \end{verbatim}
        \begin{center}
            \begin{figure}[h!]
                \centering
                \includegraphics[width=0.4\textwidth]{pictures/embedded_aruco.png}
                \caption{Marcador ArUco embebido generado.}
            \end{figure}
        \end{center}
    
        \item \textbf{Almacenamiento del marcador embebido:} 
        Finalmente, el marcador generado se guardó como una imagen PNG para su uso posterior.
        \begin{verbatim}
        cv2.imwrite(f'embedded_aruco_marker_{outer_marker_id}_{inner_marker_id}.png', 
                    e_aruco_marker)
        \end{verbatim}
    \end{enumerate}


\subsection{Detección de Marcadores e-Aruco en Tiempo Real} 
    El sistema fue diseñado para detectar marcadores Aruco en tiempo real, utilizando imágenes capturadas por una cámara conectada al dron. Este proceso se llevó a cabo mediante un nodo en ROS2 que procesa las imágenes y estima la pose de los marcadores con respecto a la cámara. El código completo se encuentra en los anexos del documento. A continuación, se describe el paso a paso del sistema:
    
    \begin{enumerate}
        \item \textbf{Publicación de imágenes desde el dron:} 
        La computadora auxiliar en el dron (companion computer) publica imágenes comprimidas capturadas por la cámara a un tópico de ROS 2 (\texttt{/camera\_image/compressed}). Estas imágenes se envían a la computadora en tierra para su procesamiento.
    
        \item \textbf{Recepción de imágenes en la computadora en tierra:} 
        Un nodo en la computadora en tierra se suscribe a las imágenes publicadas por el dron y realiza las siguientes tareas:
        \begin{itemize}
            \item Convierte las imágenes comprimidas en matrices utilizables para el procesamiento con OpenCV.
            \item Redimensiona las imágenes y las convierte a escala de grises para optimizar la detección.
        \end{itemize}
    
        \item \textbf{Detección de marcadores Aruco:} 
        Se utiliza la biblioteca OpenCV para detectar los marcadores Aruco presentes en la imagen. Los pasos incluyen:
        \begin{itemize}
            \item Uso del diccionario \texttt{DICT\_6X6\_250} para identificar marcadores específicos.
            \item Cálculo de las esquinas de los marcadores detectados mediante \texttt{aruco.detectMarkers}.
            \item Dibujo de los marcadores detectados para su visualización.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/deteccion_arucos.png}
                \caption{Detección de marcadores Aruco en la imagen procesada.}
            \end{figure}
        \end{center}
    
        \item \textbf{Estimación de la pose:} 
        Para cada marcador detectado, se calculó su posición y orientación en el espacio con respecto a la cámara. Esto se realizó utilizando la función \texttt{aruco.estimatePoseSingleMarkers}, que devuelve:
        \begin{itemize}
            \item \texttt{tvec}: Vector de traslación (\textit{x}, \textit{y}, \textit{z}) en metros.
            \item \texttt{rvec}: Vector de rotación que se convierte en ángulos de Euler (\textit{roll}, \textit{pitch}, \textit{yaw}) mediante matrices de rotación.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/calculo_pose.png}
                \caption{Representación gráfica de la posición y orientación calculada de un marcador Aruco.}
            \end{figure}
        \end{center}
    
        \item \textbf{Visualización y publicación de resultados:} 
        Los resultados obtenidos, incluyendo la pose de los marcadores, se visualizaron en tiempo real y se publicaron en un nuevo tópico de ROS 2 (\texttt{/aruco\_detection/compressed}). Las imágenes procesadas contenían:
        \begin{itemize}
            \item Marcadores detectados con esquinas resaltadas.
            \item Ejes X, Y y Z proyectados para mostrar la orientación de cada marcador.
        \end{itemize}
        \begin{center}
            \begin{figure}[h!]
                \centering
                %\includegraphics[width=0.8\textwidth]{pictures/marcadores_ejes.png}
                \caption{Imagen con marcadores detectados y ejes proyectados.}
            \end{figure}
        \end{center}
    
        \item \textbf{Correcciones de posición:} 
        Basándose en los valores de \texttt{tvec}, se calcularon las correcciones necesarias para ajustar la posición del dron con respecto al marcador, incluyendo movimientos laterales (\textit{x}), verticales (\textit{y}) y de profundidad (\textit{z}).
    
        \item \textbf{Interacción con el sistema:} 
        Los resultados de la detección de marcadores Aruco se utilizaron para visualizar la posición y orientación del drone en tiempo real, lo que permitirá posteriormente que el sistema de control pueda ajustar las mismas para su aterrizaje en la estación de carga.
    \end{enumerate}
    

\section{Sistema de Comunicación}

    \subsection{Especificaciones y Requerimientos} 
    El sistema de comunicación entre el dron y la estación de carga fue diseñado para garantizar la transferencia eficiente y en tiempo real de datos críticos. Los requisitos principales son:
    
    \begin{itemize}
        \item \textbf{Red local basada en WiFi:} 
        Proporcionar una comunicación efectiva entre los dispositivos sin necesidad de acceso a Internet.
        \item \textbf{Middleware DDS de ROS 2:} 
        Utilizar la arquitectura de nodos y tópicos de ROS 2 para gestionar la comunicación de datos entre los dispositivos conectados.
    \end{itemize}
    
    \subsection{Estructura de Comunicación} 
    
    \subsubsection{Red Local WiFi} 
    La red local fue creada utilizando un router WiFi que conecta todos los dispositivos involucrados en el sistema, incluyendo el dron, la estación de carga y la computadora en tierra. Esta configuración eliminó la necesidad de Internet, proporcionando un entorno seguro y aislado para la transmisión de datos. El dron, equipado con una computadora auxiliar, transmitió datos mediante tópicos de ROS 2, como imágenes comprimidas y mensajes de estado, hacia la estación de carga y la computadora en tierra.
    
    \begin{figure}
        \centering
        %\includegraphics[width=0.8\textwidth]{pictures/wifi_network.png}
        \caption{Diagrama de la red local WiFi utilizada en el sistema.}
    \end{figure}
    
    \subsubsection{Comunicación mediante ROS 2} 
    El sistema utilizó la arquitectura de nodos y tópicos de ROS 2 para gestionar la comunicación entre los dispositivos. Cada dispositivo en la red cumplió funciones específicas relacionadas con la publicación y suscripción de datos relevantes:
    
    \begin{itemize}
        \item \textbf{Dron:} 
        Publicó imágenes de la cámara (\texttt{/camera\_image/compressed}) y datos de estado relacionados con la batería, posición y otros parámetros críticos.
        \item \textbf{Computadora en tierra:} 
        Contiene una interfaz que se suscribió a los tópicos publicados por el dron para:
        \begin{itemize}
            \item Procesar imágenes y calcular la posición de los marcadores Aruco.
            \item Mostrar datos de estado del dron, como nivel de batería y modo de vuelo, etc. en tiempo real.
            \item Publicar comandos hacia la estación de carga, como abrir o retraer el cajón de la estación, mediante tópicos específicos.
        \end{itemize}
        \item \textbf{Estación de carga:} 
        Se suscribió a los comandos enviados desde la interfaz de la computadora en tierra para ejecutar las acciones necesarias, como la apertura y cierre del cajón.
    \end{itemize}
    
    \begin{figure}
        \centering
        %\includegraphics[width=0.8\textwidth]{pictures/ros2_comms.png}
        \caption{Diagrama de comunicación entre los dispositivos utilizando ROS 2.}
    \end{figure}
    

    




